{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ee6d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/wangyidan-slurm/anaconda3/envs/pt4dm/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b32beb",
   "metadata": {},
   "source": [
    "## 优化器\n",
    "**torch.optim**,基类optim.Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "160fd9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
    "            nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2)\n",
    "        )\n",
    "        # Conv和pooling，数据的形状会怎么变化？\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*5*5,120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120,84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84,10)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(-1,16*5*5)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "865953b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d38648",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77c7db2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f408f5a6",
   "metadata": {},
   "source": [
    "### 随机梯度下降为例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c955a6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0341,  0.1830,  0.2576, -0.1983,  0.0186,  0.0848, -0.0482, -0.0031,\n",
      "         -0.0067,  0.0926]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0341,  0.1830,  0.2576, -0.1983,  0.0186,  0.0848, -0.0482, -0.0031,\n",
      "         -0.0067,  0.0926]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(params = net.parameters(),lr=1)\n",
    "# params 优化的参数\n",
    "# lr learning rate\n",
    "# weight_decay:\n",
    "\n",
    "# 梯度清零\n",
    "optimizer.zero_grad()\n",
    "\n",
    "input = torch.randn(1,3,32,32)\n",
    "output = net(input)\n",
    "print(output)\n",
    "output.backward(output) # 反向传播\n",
    "print(output)\n",
    "\n",
    "# 优化器优化\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd9be4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    foreach: None\n",
       "    lr: 1e-05\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    dampening: 0\n",
       "    foreach: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为不同的自网络可以设置不同的学习率\n",
    "# 设置方法\n",
    "# 网络和对应的lr分别用字典封装起来\n",
    "\n",
    "optimizer = optim.SGD([\n",
    "    {'params':net.features.parameters()}, # 子网络features使用默认的学习率\n",
    "    {'params':net.classifier.parameters(),'lr':1e-2}\n",
    "],lr=1e-5)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab835847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(optimizer.param_groups) # 访问优化的参数的方法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc56cbb",
   "metadata": {},
   "source": [
    "### 新函数\n",
    "* id() 函数返回指定对象的唯一 id。\n",
    "* map() 第一个参数 function 以参数序列中的每一个元素调用 function 函数，返回包含每次 function 函数返回值的新列表。\n",
    "* filter()该接收两个参数，第一个为函数，第二个为序列，序列的每个元素作为参数传递给函数进行判断，然后返回 True 或 False，最后将返回 True 的元素放到新列表中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6d5172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新的函数\n",
    "# map，filter，id\n",
    "# \n",
    "special_layers = nn.ModuleList([net.classifier[0], net.classifier[2]]) \n",
    "special_layers_params = list(map(id,special_layers.parameters())) # 特殊的层的params，对应的id\n",
    "base_params = filter(lambda p: id(p) not in special_layers_params,net.parameters()) # 其他层的params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9b16a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    foreach: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    dampening: 0\n",
       "    foreach: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD([\n",
    "    {'params': base_params},\n",
    "    {'params': special_layers.parameters(),'lr':0.01}\n",
    "],lr=0.001)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc90e35a",
   "metadata": {},
   "source": [
    "### 调整学习率\n",
    "* 新建一个优化器，lr变成调整以后的lr，但是这样对使用动量的优化器可能会丢失状态信息\n",
    "* 直接修改优化器中的lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f0e83636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    foreach: None\n",
       "    lr: 1e-05\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    dampening: 0\n",
       "    foreach: None\n",
       "    lr: 0.010000000000000002\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 新建optimizer\n",
    "old_lr = 0.1\n",
    "optimizer1 = optim.SGD([\n",
    "    {'params':net.features.parameters()},\n",
    "    {'params':net.classifier.parameters(),'lr':old_lr*0.1}\n",
    "],lr=1e-5)\n",
    "optimizer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5e17ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    foreach: None\n",
       "    lr: 0.0001\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    dampening: 0\n",
       "    foreach: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 直接手动修改lr\n",
    "for param_group in optimizer.param_groups:\n",
    "    param_group['lr'] *= 0.1\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de65b83",
   "metadata": {},
   "source": [
    "## nn.functional\n",
    "用nn.Module实现的layers是一个特殊的类，都是由`class layer(nn.Module)`定义，会自动提取可学习的参数。而`nn.functional`中的函数更像是纯函数，由`def function(input)`定义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80b9d6d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True],\n",
       "        [True, True, True, True]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(2,3)\n",
    "model = nn.Linear(3,4)\n",
    "output1 = model(input)\n",
    "output2 = nn.functional.linear(input=input,weight=model.weight,bias=model.bias)\n",
    "\n",
    "output1 == output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4a52291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = nn.functional.relu(input)\n",
    "b2 = nn.ReLU()(input)\n",
    "b == b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07bacdd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "在模型中搭配使用`nn.Module`和`nn.functional`\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "在模型中搭配使用`nn.Module`和`nn.functional`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "954587ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=6,kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6,out_channels=16,kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(16*5*5,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84,10)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        # 这里relu，pool都直接使用functional中的function\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.pool(x,2)\n",
    "        \n",
    "        # 一行写完\n",
    "        x = F.pool(F.relu(self.conv2(x)),2)\n",
    "        x = x.view(-1,16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e617f599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手撕Linear层（x\n",
    "class MyLinear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyLinear,self).__init__()\n",
    "        # 打包成Parameter\n",
    "        self.weight = nn.Parameter(torch.randn(3,4))\n",
    "        self.bias = nn.Parameter(torch.zeros(3))\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return F.linear(x,self.weight,self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "853a1030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## 初始化策略\n",
       "PyTorch中`nn.init`模块就是专门为初始化而设计，如果某种初始化策略`nn.init`不提供，用户也可以自己直接初始化。\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "## 初始化策略\n",
    "PyTorch中`nn.init`模块就是专门为初始化而设计，如果某种初始化策略`nn.init`不提供，用户也可以自己直接初始化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32f96756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.3535,  0.1427,  0.0330],\n",
       "        [ 0.3321, -0.2416, -0.0888],\n",
       "        [-0.8140,  0.2040, -0.5493],\n",
       "        [-0.3010, -0.4769, -0.0311]], requires_grad=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn.init初始化\n",
    "from torch.nn import init\n",
    "linear = nn.Linear(3,4)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "# 初始化\n",
    "init.xavier_normal_(linear.weight) # 服从一个N(0,std)的高斯分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94f7b6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3535,  0.1427,  0.0330],\n",
       "        [ 0.3321, -0.2416, -0.0888],\n",
       "        [-0.8140,  0.2040, -0.5493],\n",
       "        [-0.3010, -0.4769, -0.0311]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "torch.manual_seed(1)\n",
    "\n",
    "std = math.sqrt(2) / math.sqrt(3+4.) # in_feature + out_feature\n",
    "linear.weight.data.normal_(0,std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "892f3b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "517614b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight\n",
      "tensor([-2.9677e-02,  2.5925e-02, -4.4038e-02, -3.5723e-02,  4.9460e-02,\n",
      "        -2.7446e-02, -4.2176e-02,  4.3130e-02,  3.3042e-02, -2.8350e-02,\n",
      "         1.0480e-02,  2.3439e-03,  2.9416e-02, -3.9736e-02, -3.2993e-02,\n",
      "        -4.0635e-02,  7.9559e-03, -4.8766e-02, -3.7929e-02,  5.7842e-03,\n",
      "         1.7950e-02,  5.9884e-03,  3.1195e-02, -1.0225e-02, -3.3703e-02,\n",
      "        -2.6772e-02,  1.7335e-03, -4.6715e-02, -3.0527e-02, -4.2052e-02,\n",
      "        -3.3746e-02, -1.0058e-02,  2.7784e-02,  1.1201e-02, -3.6287e-02,\n",
      "        -3.8815e-02,  3.1654e-02, -4.1199e-02,  1.4068e-02, -4.2106e-02,\n",
      "         2.3294e-02, -2.4933e-02, -2.9120e-02, -4.0588e-02, -2.5668e-02,\n",
      "        -1.2819e-02,  2.2915e-03, -1.7900e-02, -2.7965e-02, -3.0340e-02,\n",
      "        -4.3396e-02,  2.2986e-03,  2.6125e-02,  2.0004e-02,  3.4494e-03,\n",
      "        -6.9220e-03, -5.9373e-03,  4.8400e-02, -1.9492e-02, -7.2676e-04,\n",
      "         4.6170e-02,  5.2375e-05,  3.0104e-02, -3.4700e-02,  4.2568e-02,\n",
      "         1.2869e-02, -9.9212e-03, -8.3443e-03, -2.9653e-02,  3.9303e-02,\n",
      "         7.9088e-03, -1.6150e-02,  4.3595e-02, -4.7672e-02, -3.2047e-03,\n",
      "        -1.7765e-02,  1.5742e-02, -1.2673e-02, -2.6088e-02,  7.1867e-03,\n",
      "         1.5773e-02, -4.8559e-02, -1.6807e-02, -1.0943e-02,  7.0308e-03,\n",
      "         1.0856e-02,  2.0585e-02,  5.8261e-03, -3.1371e-02,  1.0237e-02,\n",
      "        -8.3725e-03, -1.4939e-02,  3.3894e-02, -2.0535e-02,  6.2465e-03,\n",
      "         1.1115e-03,  2.8061e-02,  3.1494e-02,  4.9286e-02, -4.7881e-02,\n",
      "         2.9232e-02,  4.3304e-02,  1.3050e-02, -2.3485e-02,  6.3705e-03,\n",
      "         4.5134e-02, -2.5181e-02, -2.1676e-02,  1.8456e-02, -1.8769e-02,\n",
      "         4.2378e-03,  9.4128e-03, -4.4532e-02,  4.1727e-02, -1.8300e-02,\n",
      "        -2.7835e-03,  4.6873e-02, -4.7075e-02, -4.2818e-03, -1.4351e-02,\n",
      "         2.9596e-02,  1.8193e-02, -1.7038e-02, -8.9831e-03,  2.7600e-02,\n",
      "         2.0575e-02,  2.9668e-03,  1.5649e-02,  3.2792e-02,  4.9565e-02,\n",
      "         1.2012e-02,  1.5482e-03, -3.0314e-02, -2.3287e-02,  1.3810e-02,\n",
      "         3.6944e-03,  2.3256e-02,  4.0244e-02, -2.1970e-02,  4.6154e-02,\n",
      "        -4.9711e-02,  1.3580e-02, -3.4426e-02, -4.3568e-02,  3.0383e-02,\n",
      "        -1.2851e-02, -2.8553e-02,  3.9984e-02,  2.0089e-02,  2.0384e-02,\n",
      "         4.5263e-02, -4.1125e-02,  1.5349e-03,  1.5506e-02, -4.1849e-02,\n",
      "         2.9381e-02, -4.6427e-02, -3.1919e-02, -4.8852e-03,  3.3959e-02,\n",
      "        -3.4234e-02, -3.5525e-02,  3.5699e-02,  5.5977e-03, -2.9361e-03,\n",
      "        -3.5596e-02, -2.1391e-02, -3.9996e-03, -1.6195e-02, -1.6307e-03,\n",
      "         4.0552e-02,  1.4639e-02, -3.5454e-02, -1.1151e-03,  2.1026e-02,\n",
      "        -6.1697e-03,  3.4125e-02,  2.3341e-02,  3.1075e-02, -3.4348e-02,\n",
      "         3.2401e-02,  2.1802e-02,  4.8911e-02,  4.3472e-02,  1.3705e-02,\n",
      "        -3.4453e-02, -3.8520e-02, -1.9252e-02, -4.3524e-02,  2.2209e-03,\n",
      "        -4.8948e-02,  3.9785e-02, -4.0603e-02, -2.2581e-02,  1.6485e-02,\n",
      "         2.0457e-02,  2.6551e-02, -3.4228e-02,  1.2552e-02,  3.3155e-02,\n",
      "         8.4237e-03,  1.4353e-03, -2.0017e-02, -1.0191e-02, -2.2465e-02,\n",
      "         1.4286e-02,  3.4502e-02,  4.1677e-03, -6.6948e-03,  1.5457e-02,\n",
      "         1.2695e-02, -1.3331e-02,  7.2742e-03,  1.2555e-02, -1.1481e-02,\n",
      "         2.5223e-02,  1.7763e-02, -3.6136e-02, -4.2825e-02, -1.8101e-02,\n",
      "         2.6485e-02,  3.8233e-02,  2.0537e-02, -1.2114e-02, -4.7545e-02,\n",
      "         3.2482e-02, -4.9671e-02,  3.4437e-02,  4.2307e-02, -4.3640e-02,\n",
      "         4.1784e-02, -9.0129e-03, -3.8890e-02, -3.1280e-03,  4.5449e-03,\n",
      "        -1.7018e-02,  9.7548e-03, -3.1803e-04,  3.1069e-02,  4.8086e-02,\n",
      "        -3.1397e-02, -4.8182e-03,  2.2068e-02, -2.2425e-02,  4.4709e-02,\n",
      "        -5.0560e-03, -2.0244e-02,  6.2456e-03, -3.4777e-03, -2.9547e-02,\n",
      "        -7.5326e-03, -4.2565e-02, -4.9035e-03,  2.2680e-02,  2.2225e-03,\n",
      "        -2.4633e-02,  4.7491e-03,  1.9865e-02, -3.8585e-02,  9.8383e-03,\n",
      "         8.0206e-03,  3.1729e-03, -3.8195e-02,  3.2126e-02,  3.3718e-02,\n",
      "        -1.5789e-02,  2.1850e-02,  3.2058e-02, -3.3450e-03,  8.1822e-03,\n",
      "         4.5616e-02,  9.2621e-03, -3.6450e-02,  3.6351e-02, -5.7364e-03,\n",
      "         3.7600e-02,  7.8728e-03,  1.0934e-02, -3.3297e-02, -3.2642e-02,\n",
      "         4.4556e-02,  1.2215e-02, -4.1432e-02,  1.4667e-02, -4.5457e-04,\n",
      "         1.8775e-03, -4.3928e-02,  3.2962e-02, -4.0312e-02,  2.2766e-03,\n",
      "        -2.5008e-02, -2.9990e-02, -4.5578e-02,  3.1756e-02,  1.7619e-02,\n",
      "         3.6419e-02, -1.8527e-02,  4.1997e-03,  4.5475e-02,  3.0748e-02,\n",
      "         4.9551e-02, -2.7351e-02,  1.2033e-02, -1.7739e-02,  1.5774e-02,\n",
      "         4.7092e-02,  3.3175e-02,  2.3555e-02, -1.9863e-02, -4.7998e-02,\n",
      "        -3.6551e-02, -3.0170e-02, -1.0756e-02, -2.3896e-02, -2.6200e-02,\n",
      "         4.1777e-05, -2.2255e-03, -4.5105e-02,  2.6775e-02, -8.4342e-03,\n",
      "         3.6708e-02, -2.2618e-02, -2.7287e-02, -3.4078e-02, -5.6588e-03,\n",
      "        -2.6443e-02, -1.3663e-02, -2.0530e-02, -1.4040e-02, -3.9253e-02,\n",
      "         1.5583e-02,  4.8253e-02,  1.7465e-02,  2.0714e-02,  5.4744e-03,\n",
      "        -3.9427e-02, -3.5802e-02,  3.4691e-02,  3.2241e-02,  2.8927e-02,\n",
      "         1.7049e-02,  1.2522e-02,  1.7786e-02, -3.5948e-02, -3.7119e-02,\n",
      "         3.0095e-02,  5.8478e-03,  5.5487e-03, -1.3541e-02, -3.1608e-02,\n",
      "        -9.0042e-03,  1.7518e-02,  3.3316e-02, -4.4698e-03,  2.6871e-03,\n",
      "         2.5609e-02,  3.8044e-02,  1.9686e-03,  2.3849e-02, -2.3499e-02,\n",
      "         1.6826e-02,  1.0119e-02, -1.0195e-02, -3.7033e-02,  5.0502e-03,\n",
      "        -1.1239e-02,  4.5123e-02,  1.7282e-02, -6.3150e-04,  4.1998e-02,\n",
      "        -4.6264e-02, -1.2373e-03,  3.7484e-02, -3.7684e-02, -4.1275e-02,\n",
      "        -4.0290e-02,  3.0671e-02, -9.8714e-03,  3.8940e-02,  3.6354e-02,\n",
      "         9.8282e-05, -3.6292e-02,  1.1281e-03,  1.6863e-02, -4.6113e-02,\n",
      "         1.4943e-02,  6.9659e-03, -3.1687e-02, -4.6720e-02,  1.9136e-02,\n",
      "         4.3997e-02,  4.9576e-02,  3.4308e-02, -1.5827e-02, -3.4735e-03,\n",
      "        -2.9556e-02,  3.4725e-02, -6.1933e-03,  1.2075e-02, -3.7648e-02],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "fc1.bias\n",
      "tensor(-0.0052, grad_fn=<SelectBackward0>)\n",
      "fc2.weight\n",
      "tensor([ 1.7353e-02, -8.4530e-02,  6.6634e-02, -8.4514e-02, -8.1745e-03,\n",
      "         1.8308e-02,  5.8171e-02,  2.7098e-02,  1.6691e-03,  7.1760e-02,\n",
      "        -3.8598e-02,  5.0711e-06, -8.8098e-02, -6.7924e-02, -4.2618e-02,\n",
      "         2.8579e-02,  6.8954e-02, -5.6004e-02,  2.6799e-02, -7.1477e-02,\n",
      "         4.0021e-02,  3.1292e-02, -5.6715e-02,  7.8176e-02,  3.8759e-02,\n",
      "         5.7632e-02, -5.2380e-02, -8.9043e-02,  4.3981e-02,  3.6483e-02,\n",
      "         7.1205e-02, -2.4704e-02,  6.3103e-03,  8.2231e-02,  4.9877e-02,\n",
      "         4.1466e-03, -1.7940e-02,  2.5700e-02,  6.4300e-02, -3.4230e-02,\n",
      "        -8.9498e-02,  7.4088e-02, -3.8436e-03,  2.3392e-02, -1.9850e-02,\n",
      "        -2.8817e-02, -3.4507e-02,  2.9591e-02, -5.4502e-02, -7.4460e-02,\n",
      "         2.1192e-02, -4.3741e-02,  3.5133e-02, -4.7629e-02,  6.4943e-02,\n",
      "        -7.2613e-03, -5.7511e-02,  3.0656e-02, -8.4252e-02, -3.1931e-02,\n",
      "        -6.7199e-02, -3.0850e-02, -5.2807e-02,  8.4948e-02, -3.6720e-03,\n",
      "        -8.6440e-02, -3.1030e-02,  8.6863e-02, -9.2846e-03,  8.8509e-02,\n",
      "         2.6662e-02, -3.1276e-02, -5.3027e-02,  5.3028e-02, -2.6730e-02,\n",
      "        -1.6967e-02, -6.7925e-02,  6.2851e-02, -2.3458e-02, -6.9563e-02,\n",
      "         8.4423e-03, -9.6177e-05,  7.6788e-02,  1.9607e-02, -2.2941e-02,\n",
      "         5.5932e-02,  3.1435e-02,  6.3924e-03,  2.3739e-02, -1.3175e-02,\n",
      "         2.1402e-02,  5.3960e-02, -4.9515e-02, -7.2268e-02, -3.6554e-02,\n",
      "         5.6269e-02,  8.5371e-02, -7.1785e-02, -6.5498e-02,  1.2596e-02,\n",
      "         3.4643e-02, -5.4908e-02, -5.3780e-02, -1.1373e-02,  2.2694e-02,\n",
      "        -4.6240e-02, -8.4357e-02,  5.9725e-02,  9.0911e-02, -5.9933e-02,\n",
      "        -2.3445e-02,  3.1683e-02,  4.2431e-03, -1.3650e-02,  1.4813e-02,\n",
      "         6.3816e-03,  8.9760e-03, -3.4086e-02,  6.1158e-02,  5.3942e-02],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "fc2.bias\n",
      "tensor(0.0528, grad_fn=<SelectBackward0>)\n",
      "fc3.weight\n",
      "tensor([ 0.1031,  0.0162, -0.0617,  0.0408, -0.0348, -0.0199,  0.0378,  0.0281,\n",
      "        -0.0088, -0.0985, -0.0778,  0.0704, -0.0513, -0.0211,  0.0243, -0.0002,\n",
      "         0.0874, -0.1086, -0.0160,  0.0958, -0.0229,  0.0086, -0.0503,  0.0629,\n",
      "        -0.0324,  0.0941, -0.1036, -0.1053,  0.0401,  0.0054, -0.0719, -0.0185,\n",
      "         0.0340, -0.0552,  0.0621,  0.0884, -0.0749, -0.0235, -0.0711,  0.0192,\n",
      "        -0.0283, -0.0329, -0.0095,  0.0778,  0.0682,  0.0077,  0.0814, -0.0059,\n",
      "         0.0751, -0.0105,  0.0208,  0.0408,  0.0909, -0.0237, -0.0595, -0.0528,\n",
      "         0.0287, -0.0939,  0.0482, -0.0773, -0.0985,  0.0827,  0.0607, -0.0877,\n",
      "         0.0298, -0.0025, -0.0904,  0.0397,  0.0207, -0.0069, -0.0286,  0.0415,\n",
      "        -0.0403, -0.0903, -0.0080,  0.0174,  0.0662,  0.1090,  0.0030, -0.0013,\n",
      "        -0.0259, -0.0027, -0.0407, -0.0272], grad_fn=<SelectBackward0>)\n",
      "fc3.bias\n",
      "tensor(-0.0646, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 模型参数初始化\n",
    "for name,params in net.named_parameters():\n",
    "    if name.find('fc') != -1:\n",
    "        #  init linear\n",
    "        print(name)\n",
    "        print(params[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88db0c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt4dm",
   "language": "python",
   "name": "pt4dm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
